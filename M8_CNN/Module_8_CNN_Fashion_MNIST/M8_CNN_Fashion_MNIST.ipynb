{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ebb47d-d044-43bc-9283-d8f0a1f98663",
   "metadata": {},
   "source": [
    "# <center> Classify items in the fashion MNIST Dataset using a CNN  </center> <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8fafe4-e0c4-4a33-9d7d-9d2b1c10038d",
   "metadata": {},
   "source": [
    "### This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. \n",
    "\n",
    "\n",
    "Data: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1ac8e-5352-431b-b930-6095a9ea4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0c868-af5f-435b-bfae-ef53ea687ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "assert X_train.shape == (60000, 28, 28)\n",
    "assert X_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a094984-1618-44c3-8e25-1e055752a886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea28a75c-5f92-4469-976c-c22da4311949",
   "metadata": {},
   "source": [
    "# Visualize data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d057a-2fab-4709-abf9-50a4ce723fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train-set data shape = \", X_train.shape)\n",
    "print(\"Train-set labels shape = \", y_train.shape)\n",
    "\n",
    "print(\"Test-set data shape = \", X_test.shape)\n",
    "print(\"Test-set data shape = \", y_test.shape)\n",
    "\n",
    "print(\"Show Classes = \", np.unique(y_test))\n",
    "print(\"Show Nr. of classes = \", len(np.unique(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acca3935-f4b9-41f4-8872-c2e71373b6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "035a3f1e-7b8e-408a-8904-af13592631b4",
   "metadata": {},
   "source": [
    "# Display a random training sample from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa123a16-4108-4210-90bd-a07e2137aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_ids = np.unique(y_train)\n",
    "f, axes = plt.subplots(len(classes_ids),1, figsize=(2, len(classes_ids)*2))\n",
    "f.tight_layout()\n",
    "\n",
    "for cidx, class_id in enumerate(classes_ids):\n",
    "    class_samples_idxs = np.argwhere(y_train == class_id).ravel()\n",
    "    range_sel = np.random.randint(0, len(class_samples_idxs)-1, 1, dtype=int)\n",
    "    image_idx = class_samples_idxs[int(range_sel)]\n",
    "    \n",
    "    class_label = y_train[image_idx]\n",
    "    image_obj = X_train[image_idx]\n",
    "\n",
    "    ax=axes[cidx]\n",
    "    ax.imshow(image_obj)\n",
    "    ax.set_title(f\"Label={class_label}\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ea235-37b3-42aa-b267-a88afbed539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a sample\n",
    "image_idx=int(X_train.shape[0]/2)\n",
    "picture = X_train[image_idx]\n",
    "print(picture.shape)\n",
    "#picture = picture.reshape(28,28) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6abc1-b624-4379-98c8-3e8e20657a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the sample label\n",
    "lbl = y_train[image_idx]\n",
    "print(f\"Sample {image_idx}, label = {y_train[image_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b9b6a-de14-4012-92e0-9ff27667869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the handwritten digit image\n",
    "plt.imshow(picture)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af20756-e22a-4a6f-bcd2-058b67aeeb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d91a470-c6a8-454d-8b77-27a5fd5ebb0d",
   "metadata": {},
   "source": [
    "# Reshape the data. Images are 28x28 and 1 Channel (gray scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a0018-0721-48a6-b058-9a520d2231ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef1a806-0134-419f-94eb-684dfbc863aa",
   "metadata": {},
   "source": [
    "# Normalize the data between 0 and 1 (colors are coded from 0 to 255 so just divide by 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ded68b-a1d1-430a-bab3-9a72ec7ed841",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be7741-d101-4499-b685-db62ec84a8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d69493c1-0382-40b1-83e3-135f9c9ad92d",
   "metadata": {},
   "source": [
    "### Define the CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76413cd6-2846-489e-a526-ec891e8353f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Accuracy = 0.9937000274658203\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
    "# Max Pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Dropout layer\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "# Convolutional Layer\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(28, 28, 3), activation='relu'))\n",
    "# Convolutional Layer\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(28, 28, 3), activation='relu'))\n",
    "# Max Pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Dropout layer\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "#add flattening layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Full connection\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Full connection\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100073d8-0842-4876-9448-d57248f328a5",
   "metadata": {},
   "source": [
    "# Compile CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea35c5d4-12e7-471c-bb82-2e141791c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881ddac-2b47-48b2-9a02-1d8f92b94829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feb0249c-2a35-4081-bd66-11287167c533",
   "metadata": {},
   "source": [
    "# Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcebc76-c208-4cc3-a441-a15c3e44383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[PlotLossesKeras()],\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3455608d-1cff-4749-8ed9-649308e1b848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451282f-8693-4508-b1c5-2d9937f23f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model's performance\n",
    "loss, accuracy = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d0df46-0fcd-42dd-ab82-7d75f9160325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loss (sparse_categorical_crossentropy) = {loss}\")\n",
    "print(f\"Accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a195dc4f-4d5b-44b8-b0be-5f653ac0a887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
